import os
import speech_recognition as sr
import librosa
import numpy as np
import matplotlib.pyplot as plt
import librosa.display
from gtts import gTTS

FLUENT_THRESHOLD = 0.5  # You can adjust this threshold based on your preference

def recognize_speech():
    recognizer = sr.Recognizer()

    with sr.Microphone() as source:
        print("Say something:")
        try:
            # Record audio for 10 seconds
            audio = recognizer.listen(source, timeout=10)
            print("Recording complete.")
        except sr.WaitTimeoutError:
            print("Recording timed out after 10 seconds.")
            return None

    try:
        text = recognizer.recognize_google(audio)
        print("You said:", text)
        return text
    except sr.UnknownValueError:
        print("Sorry, could not understand audio.")
        return None
    except sr.RequestError as e:
        print("Error connecting to Google API: {0}".format(e))
        return None

def check_pronunciation(original_text, recognized_text):
    print("\nOriginal Text:", original_text)
    print("Recognized Text:", recognized_text)

    if original_text.lower() == recognized_text.lower():
        print("Pronunciation is correct!")
    else:
        print("Pronunciation is incorrect.")

        # Text-to-Speech synthesis for the correct pronunciation
        tts = gTTS(original_text)
        tts.save("correct_pronunciation.mp3")
        os.system("correct_pronunciation.mp3")

def calculate_fluency_score(spectrogram):
    # Your fluency score calculation logic here
    pass

def calculate_single_fluency_score(spectrogram):
    fluency_scores = calculate_fluency_score(spectrogram)
    single_fluency_score = np.mean(fluency_scores)
    return single_fluency_score

def main():
    original_text = "Hello, how are you?"
    recognized_text = recognize_speech()

    if recognized_text:
        check_pronunciation(original_text, recognized_text)

    audio_file = "C:/Users/windows 11/Documents/video_audio3.mp3"
    y, sr = librosa.load(audio_file, sr=None)

    hop_length = 512
    S = librosa.feature.melspectrogram(y=y, sr=sr, hop_length=hop_length)

    fluency_score = calculate_single_fluency_score(S)
    print("Fluency Score:", fluency_score)

    # Rest of your pitch-related code here

    # Thresholding: classify segments as fluent or disfluent
    fluent_segments = np.where(fluency_score > FLUENT_THRESHOLD)[0]
    disfluent_segments = np.where(fluency_score <= FLUENT_THRESHOLD)[0]

    # Plot the spectrogram
    plt.figure(figsize=(10, 6))
    librosa.display.specshow(librosa.power_to_db(S, ref=np.max), sr=sr, x_axis='time', y_axis='linear')
    plt.colorbar(format='%+2.0f dB')
    plt.show()

if __name__ == "__main__":
    main()
